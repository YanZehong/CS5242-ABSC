{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7820b93a",
   "metadata": {},
   "source": [
    "### Scrap TripAdvisor data by selenium\n",
    "1.Please running on your own jupyter notebook.\n",
    "\n",
    "2.Please install selenium,BeautifulSoup4,pandas before you run the code:\n",
    "```\n",
    "!pip install selenium\n",
    "!pip install bs4\n",
    "!pip install pandas\n",
    "```\n",
    "3.Please download the webdriver corresponding to your chrome browser version into the same diretory with this notebook.\n",
    "\n",
    "https://chromedriver.chromium.org/\n",
    "\n",
    "4.Every time you run the code, data will be crawled according to the input: url and pages.\n",
    "\n",
    "Here is a document for our total dataset.\n",
    "\n",
    "https://www.showdoc.com.cn/2091238148777763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "result_backup=[]\n",
    "def pages(url,page_number):\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    print(f'Logging in...')\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    result=[]\n",
    "    for j in range(page_number):\n",
    "        try:\n",
    "            print(j)\n",
    "            try:\n",
    "                button=driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/div[9]/div/div[1]/div[1]/div/div/div[3]/div[3]/div[2]/div[3]/div[1]/div[2]/div/span[1]\")\n",
    "            except:\n",
    "                try:\n",
    "                    button=driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/div[9]/div/div[1]/div[1]/div/div/div[3]/div[3]/div[3]/div[3]/div[1]/div[2]/div/span[1]\")\n",
    "                except:\n",
    "                    button=driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/div[9]/div/div[1]/div[1]/div/div/div[3]/div[13]/div/a[2]\")\n",
    "                    button.click()\n",
    "                    time.sleep(3)\n",
    "            if button.text=='Read more':\n",
    "                button.click()\n",
    "\n",
    "            for i in range(3,13):\n",
    "                dic={}\n",
    "                path = '/html/body/div[2]/div[2]/div[2]/div[9]/div/div[1]/div[1]/div/div/div[3]/div[%s]'%str(i)\n",
    "                comment = driver.find_element(\"xpath\",path)\n",
    "                soup = BeautifulSoup(comment.get_attribute('innerHTML'), 'html.parser')\n",
    "                bubble_rating = list(soup.find_all('span',\"ui_bubble_rating\"))\n",
    "                aspect=list(soup.find_all('div','hemdC S2 H2 WWOoy'))\n",
    "                \n",
    "#                 if int(bubble_rating[0].attrs['class'][1].replace('bubble_',''))>30:\n",
    "#                     pass\n",
    "#                 else:\n",
    "                dic['overall']=bubble_rating[0].attrs['class'][1].replace('bubble_','')\n",
    "                for i in range(len(aspect)):\n",
    "                    dic[aspect[i].get_text()] = bubble_rating[i+1].attrs['class'][1].replace('bubble_','')\n",
    "#                     if i == 0:\n",
    "#                         dic['overall']=bubble_rating[i].attrs['class'][1].replace('bubble_','')\n",
    "#                     elif i ==1:\n",
    "#                         dic['value']=bubble_rating[i].attrs['class'][1].replace('bubble_','')\n",
    "#                     elif i ==2:\n",
    "#                         dic['cleanliness']=bubble_rating[i].attrs['class'][1].replace('bubble_','')\n",
    "#                     elif i ==3:\n",
    "#                         dic['service']=bubble_rating[i].attrs['class'][1].replace('bubble_','')\n",
    "                if 'Location' not in dic:\n",
    "                    pass\n",
    "                else:\n",
    "                    soup.find_all('a')[2].get_text()\n",
    "                    dic['title'] = soup.find_all('a')[2].get_text()\n",
    "                    dic['review'] = soup.find_all('q')[0].get_text()\n",
    "                    dic['date'] = soup.find_all('span','teHYY _R Me S4 H3')[0].get_text()\n",
    "                    result.append(dic)\n",
    "                    result_backup.append(dic)\n",
    "            if j ==0:\n",
    "                button=driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/div[9]/div/div[1]/div[1]/div/div/div[3]/div[13]/div/a\")\n",
    "                button.click()\n",
    "            else:\n",
    "                button=driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/div[9]/div/div[1]/div[1]/div/div/div[3]/div[13]/div/a[2]\")\n",
    "                button.click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            button=driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/div[9]/div/div[1]/div[1]/div/div/div[3]/div[13]/div/a[2]\")\n",
    "            button.click()\n",
    "            time.sleep(3)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####for running\n",
    "url = 'https://www.tripadvisor.com/Hotel_Review-g186338-d193166-Reviews-Pembridge_Palace_Hotel-London_England.html'\n",
    "one_page_data = pages(url,76)\n",
    "df = pd.DataFrame(data=one_page_data)\n",
    "\n",
    "df = df[df[['Value','Location','Service','Rooms','Cleanliness','Sleep Quality']].notnull().any(1)]\n",
    "\n",
    "order = ['overall','title','review','date','Value','Location','Service','Rooms','Cleanliness','Sleep Quality']\n",
    "df = df[order]\n",
    "\n",
    "df.to_excel('scrap_data.xlsx',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
